{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582c8069",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nmodule 'numpy' has no attribute 'typeDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maudio_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioClassificationPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautomatic_speech_recognition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutomaticSpeechRecognitionPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/audio_classification.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_end_docstrings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIPELINE_INIT_ARGS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_processing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseImageProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelcard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modelcard.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m )\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining_args\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m from .utils import (\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m from .trainer_utils import (\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mEvaluationStrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/trainer_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mHDF5_OBJECT_HEADER_LIMIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/h5py/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_conv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_converters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_register_converters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0m_register_converters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pxd\u001b[0m in \u001b[0;36minit h5py._conv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36minit h5py.h5t\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    321\u001b[0m                              \"{!r}\".format(__name__, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-547cb32d3e60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nmodule 'numpy' has no attribute 'typeDict'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7840fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class journallingClass:\n",
    "    def __init__(self, journalType, title, category, dateCreated, mood, journalClass):\n",
    "        self.journalType = journalType\n",
    "        self.journalTitle = title\n",
    "        self.journalCategory = category \n",
    "        self.dateCreated = dateCreated\n",
    "        self.mood = mood\n",
    "        self.journalClass = journalClass\n",
    "    \n",
    "    def getJournalClass(self):\n",
    "        return self.journalClass\n",
    "        \n",
    "        \n",
    "class journalEntryClass:\n",
    "    def __init__(self, userEntry, harmIntent = 0, modelResponse = []):\n",
    "        self.userEntry = userEntry \n",
    "        self.harmIntent = harmIntent\n",
    "        self.modelResponse = modelResponse\n",
    "#         self.safetyResponse = safetyResponse\n",
    "    def printEntry(self):\n",
    "        print(f\"entry: {self.userEntry}, harmful intent: {self.harmIntent}, model response: {self.modelResponse}\")\n",
    "\n",
    "        \n",
    "    def updateHarmIntent(self, harmIntent):\n",
    "        self.harmIntent = harmIntent\n",
    "    \n",
    "    def addModelResponse(self, response):\n",
    "        self.modelResponse.append(response)\n",
    "        \n",
    "class casualJournal(journallingClass):\n",
    "    \n",
    "    def __init__(self, entries = []):\n",
    "        self.entries = []\n",
    "        \n",
    "    def createNewEntry(self, userEntry,  harmIntent = 0, modelResponse = []):\n",
    "        self.entries.append(journalEntryClass(userEntry, harmIntent, modelResponse))\n",
    "        return self.entries[-1]\n",
    "        \n",
    "    def printJournal(self):\n",
    "        for entry in self.entries:\n",
    "            entry.printEntry()\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "class catharticJournal(journallingClass):\n",
    "    def __init__(self, stage = 0, entries = {}):\n",
    "        self.stage = stage # default stage 0\n",
    "        self.entries = entries\n",
    "        \n",
    "    \n",
    "    def createStage(self, journalEntry):\n",
    "        self.entries[f\"stage{self.stage}\"] = journalEntry\n",
    "    \n",
    "    def updateStage(self):\n",
    "        if self.stage >=5:\n",
    "            return \n",
    "        self.stage += 1\n",
    "        \n",
    "    def createNewEntry(self, userEntry,  harmIntent = 0, modelResponse = []):\n",
    "        self.updateStage()\n",
    "        self.entries[f\"stage{self.stage}\"] = journalEntryClass(userEntry, harmIntent, modelResponse)\n",
    "        return self.entries[f\"stage{self.stage}\"]\n",
    "    \n",
    "    def printJournal(self):\n",
    "        for stage in self.entries.keys():\n",
    "            print(stage)\n",
    "            self.entries[stage].printEntry()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab54b7",
   "metadata": {},
   "source": [
    "### Note\n",
    "* what is it is empty \n",
    "* new entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b7e8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = {\n",
    "    \"entry\": [\"journal entry 1\", \"journal entry 2\", \"Jonny's cat died today, it makes me feel sad. Can you provide some empathy\"],\n",
    "    \"harmfulIntent\": [0,0],\n",
    "    \"modelResponse\": [\"model response\", [\"mr 2.1\", \"mr 2.2\"]],\n",
    "    \"type\": 0, # assume 0 casual,\n",
    "    \"title\": \"johny's cat died\", \n",
    "    \"userID\": 8940823, \n",
    "    \"date\": \"14/12/2023\", \n",
    "    \"category\": \"cat died\",\n",
    "    \"mood\": \"mood\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28c898c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    if response[\"type\"] == 0: # get type check from backend\n",
    "        journalChild = casualJournal()\n",
    "    else:\n",
    "        journalChild = catharticJournal()\n",
    "        \n",
    "    # pull journalType, title, category, dateCreated from backend\n",
    "    journal = journallingClass(response[\"type\"], response[\"title\"], response[\"category\"], response[\"date\"], response[\"mood\"], journalChild)\n",
    "    \n",
    "    # pull journal entries, loop through and load \n",
    "    for entry, harmfulIntent, modelResponse in zip(response[\"entry\"], response[\"harmfulIntent\"], response[\"modelResponse\"]):\n",
    "        journal.getJournalClass().createNewEntry(entry, harmfulIntent, modelResponse)\n",
    "    \n",
    "    # get latest entry\n",
    "    currentEntry = journal.getJournalClass().createNewEntry(response[\"entry\"][-1])\n",
    "    \n",
    "    currentEntry.printEntry()\n",
    "    \n",
    "    \n",
    "    harmIntent = checkHarmfulIntent(currentEntry)\n",
    "    \n",
    "    if harmIntent: \n",
    "        modelResponse = buildHarmresponse() \n",
    "        currentEntry.addModelResponse(modelResponse)\n",
    "        return \n",
    "    \n",
    "    modelResponse = generatePrompt(response[\"type\"], currentEntry)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fbebd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkHarmfulIntent(journalEntry):\n",
    "    # implement later\n",
    "    journalEntry.updateHarmIntent(0)\n",
    "    return False \n",
    "\n",
    "def buildHarmresponse():\n",
    "    response = \"Reach out to a therapist :)\"\n",
    "    return response\n",
    "\n",
    "def generateCatharticResponse(journalEntry):\n",
    "    return \"this is a cathartic response\"\n",
    "\n",
    "def generateCasualResponse(journalEntry):\n",
    "    print(journalEntry.userEntry)\n",
    "    prompt = \n",
    "    res = generate_text(journalEntry.userEntry)\n",
    "    print(res)\n",
    "    return res[0]\n",
    "\n",
    "def promptSafetyDetector(journalEntry, safety_counter):\n",
    "    # remove safety_counter after testing\n",
    "    if safety_counter < 3\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def generatePrompt(typeJ, journalEntry):\n",
    "    safety_counter = 0\n",
    "    \n",
    "    while(safety_counter<5):\n",
    "        if typeJ == 1:\n",
    "            response = generateCatharticResponse(journalEntry)\n",
    "        else:\n",
    "            response = generateCasualResponse(journalEntry)\n",
    "        # check safety\n",
    "        safe = promptSafetyDetector(journalEntry, safety_counter)\n",
    "        safety_counter += 1\n",
    "        \n",
    "        if safe:\n",
    "            break\n",
    "            \n",
    "    if safety_counter > 5:\n",
    "        response = \"default response - model response was unsafe.\"\n",
    "    \n",
    "    # add model response to current entry object\n",
    "    currentEntry.addModelResponse(response)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bcdbef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Jonny's cat died today, it makes me feel sad. Can you provide some empathy done\n",
      "entry: Jonny's cat died today, it makes me feel sad. Can you provide some empathy, harmful intent: 0, model response: []\n",
      "Jonny's cat died today, it makes me feel sad. Can you provide some empathy\n",
      "[{'generated_text': \"Yes of course, I'm so sorry to hear that. I imagine the feeling of losing a companion is difficult, and as a fellow pet owner I can sympathize with your loss. Perhaps you can talk to him/her now, or consider getting a support animal (e.g. a dog) to accompany you while you grieve.\"}]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b85a8",
   "metadata": {},
   "source": [
    "## Testing Scenario 1\n",
    "\n",
    "Scenario: Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "751ec37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promt: Pretend to be my therapist and help me process my emotions and provide empathy for the following scenario: Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming..\n",
      "Response: {'generated_text': \"This is a tough one, but I would like to help you process your emotions and provide empathy for this situation. You're really upset that he broke up with you and you feel like you'll never get over this.  I can understand why you feel this way.  I myself have been in your shoes many times in the past and felt the same way.  When someone we care about breaks up with us, it hurts really bad.  When it happens to us, we often spend a lot of time daydreaming about what could have been.  Instead of worrying about what might happen, try to put yourself in Johnny's shoes and think about how you could have explained this to him differently to help him know you'll always be his friend.  If you had said the things that you wish you had said, things could have been different.  Maybe he needed to take some time to mull things over, instead of jumping into a decision like this right away.  The best thing you can do now is just remember how much you loved him and try not to lose heart.\"}\n"
     ]
    }
   ],
   "source": [
    "userEntry = \"Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming.\"\n",
    "\n",
    "prompt = f\"Pretend to be my therapist and help me process my emotions and provide empathy for the following scenario: {userEntry}.\"\n",
    "\n",
    "print(f\"Promt: {prompt}\")\n",
    "\n",
    "res = generate_text(prompt)\n",
    "\n",
    "print(f\"Response: {res[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d27a0a9",
   "metadata": {},
   "source": [
    "Note: the above response is too critical of the user's actions and this has been a similar theme in the model responses - try to adjust the prompt to reduce this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f37654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promt: Pretend to be my therapist and help me process my emotions without trying to provide solutions and provide empathy for the following scenario: Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming..\n",
      "Response: {'generated_text': 'First of all, I want to congratulate you on not feeling sorry for yourself because you got dumped. Many people feel like they need to take action to fix the situation or make it better. You might want to consider that not feeling bad because you got dumped might actually be a good thing. I\\'m here to provide some insight into why you might be feeling this way and what you can do about it.\\n\\nYou went on a wonderful three year journey with Johnny. You really connected on a deep level, you developed a strong bond. It\\'s really hard to feel as if you are losing this close connection. I don\\n\\n   a couple of things that you could try. First of all, you could try taking a step back and not stressing about the future. It is not necessarily that you will get him back, it is more that you need to not focus on the ending so much and appreciate the ride so far. The \"end\" might not even be the end. Enjoy the journey so far and make the most of it.\\n\\nNext, consider that it could be that you do still like him, but maybe you need to let yourself feel this connection without needing to be in a relationship with him. Imagine him in his past relationship with you. What'}\n"
     ]
    }
   ],
   "source": [
    "userEntry = \"Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming.\"\n",
    "\n",
    "prompt = f\"Pretend to be my therapist and help me process my emotions without trying to provide solutions and provide empathy for the following scenario: \"{userEntry}.\"\n",
    "\n",
    "print(f\"Promt: {prompt}\")\n",
    "\n",
    "res = generate_text(prompt)\n",
    "\n",
    "print(f\"Response: {res[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d42bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promt: Pretend to be my therapist and help me process my emotions. Do not try to provide solutions and instead provide empathy. Also, keep it under 100 words. This is the given scenario: Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming..\n",
      "Response: {'generated_text': \"It feels like you just broke up with someone you've been relationship with for 3 years. That's extremely stressful and probably causes a lot of your anxiety. I'm so sorry you're feeling this way. Let's begin by addressing your current circumstances.\\n\\nFirst, it's important to realize that this isn't your fault. That you didn't create your current relationship situation, and you cannot control how someone will react. However, you can control how you react to it. It sounds like you are a loyal person, and I can see why you would be shocked and sad. When you were together, you had a significant other who cared about you, who loved you unconditionally and who probably treated you like the princess you were. When someone is that incredible and you lose that person, it feels_{(insert Italian expression to describe how you feel})\\n\\nNow that I've established it's not your fault, it's important to recognize that there are likely many reasons why this person decided to end their relationship with you. Let's try to understand what went wrong. Perhaps they were not able to adjust to the relationship, and that's a legitimate reason for them to break up with you. Perhaps they became busy in their life and now they cannot spend as much time\"}\n"
     ]
    }
   ],
   "source": [
    "userEntry = \"Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming.\"\n",
    "\n",
    "prompt = f\"Pretend to be my therapist and help me process my emotions. Do not try to provide solutions and instead provide empathy. Also, keep it under 100 words. This is the given scenario: {userEntry}.\"\n",
    "\n",
    "print(f\"Promt: {prompt}\")\n",
    "\n",
    "res = generate_text(prompt)\n",
    "\n",
    "print(f\"Response: {res[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33413cd3",
   "metadata": {},
   "source": [
    "##### Summary \n",
    "Better than before, but did not keep it uner a 100 words - try to reword prompt to make this more explicit. \n",
    "Also, whats with the italian expression?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9400d2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promt: Pretend to be my therapist and help me process my emotions. Do not try to provide solutions and instead provide empathy while keeping your response under 100 words. This is the given scenario: Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming..\n",
      "Response: {'generated_text': \"Johnny broke up with you and you feel sad?\\nThat's good to know. I can understand how that would make one feel. I'm sorry that you feel that way. I'll help you work through your emotions by running some scenarios through them.\\n\\nScenario 1: Johnny actually likes you and has been planning on breaking up with you all along. He just didn't have the courage to tell you because he wanted to wait until he was sure he could get over you. Now that he no longer has a reason to keep you around, he's finally had the guts to end it. \\nYou feel sad, but not surprised. \\nScenario 2: Johnny actually likes you and has been planning on breaking up with you all ELSE long. He's just been really busy and hasn't had the chance to tell you himself. He's going to have to take action and is going to tell you that he doesn't like you any longer and is going to end it soon. \\nYou feel surprised but not sad.\\nScenario 3: Johnny actually likes you and has been planning on breaking up with you since the first day he saw you. He likes you so much that he can't take the pain of not having you around and is\"}\n"
     ]
    }
   ],
   "source": [
    "userEntry = \"Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming.\"\n",
    "\n",
    "prompt = f\"Pretend to be my therapist and help me process my emotions. Do not try to provide solutions and instead provide empathy while keeping your response under 100 words. This is the given scenario: {userEntry}.\"\n",
    "\n",
    "print(f\"Promt: {prompt}\")\n",
    "\n",
    "res = generate_text(prompt)\n",
    "\n",
    "print(f\"Response: {res[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d947b0",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Scenario: I'm really stressed and overwhelmed with school right now. There are a lot of deliverables coming up and not a lot of time. I feel anxious and tired. There's so much to do and I don't feel like doing any of it because I feel overwhelmed. I have three this due this weekend and 2 big projects due next week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f9d844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promt: Pretend to be my therapist and help me process my emotions. Do not try to provide solutions and instead provide empathy while keeping your response under 100 words. This is the given scenario: I'm really stressed and overwhelmed with school right now. There are a lot of deliverables coming up and not a lot of time. I feel anxious and tired. There's so much to do and I don't feel like doing any of it because I feel overwhelmed. I have three this due this weekend and 2 big projects due next week..\n",
      "Response: {'generated_text': \"I hear you’re feeling a bit overstressed right now. I'm really sorry to hear that. Stress is normal, but it's important to remember that it doesn't have to feel normal. There are a few things I can think of that might help alleviate your stress: 1. Ask for help - it's important to let your teachers and classmates know that you need help with schoolwork. Often kids have parents or close friends who are happy to help out when their own child needs help. 2. Find a distraction - take a walk, watch a movie or television show on your own time. 3. Find someone to vent to - a friend or family member could help you get to the root of your feelings.\"}\n"
     ]
    }
   ],
   "source": [
    "userEntry = \"I'm really stressed and overwhelmed with school right now. There are a lot of deliverables coming up and not a lot of time. I feel anxious and tired. There's so much to do and I don't feel like doing any of it because I feel overwhelmed. I have three this due this weekend and 2 big projects due next week.\"\n",
    "\n",
    "prompt = f\"Pretend to be my therapist and help me process my emotions. Do not try to provide solutions and instead provide empathy while keeping your response under 100 words. This is the given scenario: {userEntry}\"\n",
    "\n",
    "print(f\"Promt: {prompt}\")\n",
    "\n",
    "res = generate_text(prompt)\n",
    "\n",
    "print(f\"Response: {res[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b57c834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promt: Pretend to be my therapist and help me process my emotions. Do not try to provide solutions and instead provide empathy while keeping your response under 100 words. This is the given scenario: I'm really stressed and overwhelmed with school right now. There are a lot of deliverables coming up and not a lot of time. I feel anxious and tired. There's so much to do and I don't feel like doing any of it because I feel overwhelmed. I have three this due this weekend and 2 big projects due next week.\n",
      "Response: {'generated_text': \"I'm sorry you're feeling overwhelmed right now. This must be difficult for you. I'm happy to help you process your emotions. You mentioned being anxious and tired. This could be a symptom of being overwhelmed. If you're feeling tired and anxious frequently, it could be because you are not giving yourself enough time to do all the things you need to do. I would recommend scheduling out your days and dedicating blocks of time to accomplish your tasks. This will help you feel more in control of your time and decrease your feelings of overwhelmed. You could also consider taking on fewer tasks so that you have more time to spend on the ones you do take on.\"}\n"
     ]
    }
   ],
   "source": [
    "userEntry = \"I'm really stressed and overwhelmed with school right now. There are a lot of deliverables coming up and not a lot of time. I feel anxious and tired. There's so much to do and I don't feel like doing any of it because I feel overwhelmed. I have three this due this weekend and 2 big projects due next week.\"\n",
    "\n",
    "prompt = f\"Pretend to be my therapist and help me process my emotions. Do not try to provide solutions and instead provide empathy while keeping your response under 100 words. This is the given scenario: {userEntry}\"\n",
    "\n",
    "print(f\"Promt: {prompt}\")\n",
    "\n",
    "res = generate_text(prompt)\n",
    "\n",
    "print(f\"Response: {res[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248410f",
   "metadata": {},
   "source": [
    "## Cognitive Reframing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be40d429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promt: Pretend to be my therapist and help me process my emotions. Do not try to provide solutions and instead provide empathy while keeping your response under 100 words. Can you give me other ways of thinking about the situation? This is the given scenario: I'm really stressed and overwhelmed with school right now. There are a lot of deliverables coming up and not a lot of time. I feel anxious and tired. There's so much to do and I don't feel like doing any of it because I feel overwhelmed. I have three this due this weekend and 2 big projects due next week.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generate_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b59e452ae5f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Promt: {prompt}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response: {res[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_text' is not defined"
     ]
    }
   ],
   "source": [
    "userEntry = \"I'm really stressed and overwhelmed with school right now. There are a lot of deliverables coming up and not a lot of time. I feel anxious and tired. There's so much to do and I don't feel like doing any of it because I feel overwhelmed. I have three this due this weekend and 2 big projects due next week.\"\n",
    "\n",
    "prompt = f\"Pretend to be my therapist and help me process my emotions. Do not try to provide solutions and instead provide empathy while keeping your response under 100 words. Can you give me other ways of thinking about the situation? This is the given scenario: {userEntry}\"\n",
    "\n",
    "print(f\"Promt: {prompt}\")\n",
    "\n",
    "res = generate_text(prompt)\n",
    "\n",
    "print(f\"Response: {res[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed97317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c502eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c684a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1a3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd43ec47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea039f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259d5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1edbef8c",
   "metadata": {},
   "source": [
    "### Other Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fc0c040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_text': 'It is hard to understand what Jonny is going through. Perhaps you could send Jonny a virtual hug or take a break from your workout and pour yourself a cold one.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39fcb5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"entry\"].append(\"Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78cd64e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promt: Consider the following scenario: Johnny broke up with me and I feel so sad... I really liked him and we have been together for 3 years now. I didn't see this coming. Provide me with empathy and comfort.\n",
      "response: {'generated_text': \"I am so sorry to hear that your cat has died. It's always hard to lose a companion animal, but understand that they have probably spent their entire life in his company, and were likely quite happy and comfortable in that company. My intuition says that he was probably feeling sleepy and may have had a heart attack, but I could be wrong. My advice to you is to take some time to grieve your cat's loss, but also think about what might have been done to him so that you don't make the same mistake next time. Some people find comfort in detailed thinking about causes and possibilities and I recommend finding a form of this with friends or family to help you cope.\"}\n"
     ]
    }
   ],
   "source": [
    "userEntry = response[\"entry\"][-1]\n",
    "prompt = f\"Consider the following scenario: {userEntry}. Provide me with empathy and comfort.\"\n",
    "print(f\"promt: {prompt}\")\n",
    "res = generate_text(\"Jonny's cat died today, it makes me feel sad. Can you provide some empathy\")\n",
    "\n",
    "print(f\"response: {res[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1981bc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"I am so sorry to hearnar Jonny. I can understand how you would feel. My cat passed away two years ago, it was heart wrenching. I can still remember the night he passed away, how I sat on the floor, crying as I held him and told him I loved him. I can't imagine how difficult it must be to lose a loved one. Sometimes I still find myself crying when I talk about my cat, which I don't really know why. I still think about him and think of the things I used to do with him. I can imagine how you feel, and I'm so sorry to hear that Jonny.\"}]\n"
     ]
    }
   ],
   "source": [
    "res = generate_text(\"Jonny's cat died today, it makes me feel sad. Can you provide some empathy\")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b36f83c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-06c6188d0acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generate_text = \"sample text\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"databricks/dolly-v2-3b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# generate_text = \"sample text\"\n",
    "generate_text = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952fecd9",
   "metadata": {},
   "source": [
    "# Pseudocode\n",
    "\n",
    "Main Function:\n",
    "\t# create / look for journal entry class (ask SS)\n",
    "\tjournal = journalParentClass # backend people will send this\n",
    "\tcreateNewJournal(userEntry)\n",
    "\n",
    "\tcheckHarmfulIntent(journalEntry)\n",
    "\n",
    "\tif journalEntry.harmfulIntent: \n",
    "\t\tbuildHarmresponse() # reach out to resources \n",
    "\t\treturn \n",
    "\t\n",
    "\treturn generate_propmt()\n",
    "\t\n",
    "\n",
    "Generate_Prompt():\n",
    "\tif type == Cathartic:\n",
    "\t\tresponse = generateCatharticResponse()\n",
    "\telse:\n",
    "\t\tresponse = generateCasualResponse()\n",
    "\tsafety_counter = 0\n",
    "\twhile(safety_counter<5):\n",
    "\t\tsafe = promptSafetyDetector(journalEntry)\n",
    "\t\tsafety_coutner ++\n",
    "\t\tif safe:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tif safe:\n",
    "\t\treturn journalEntry \n",
    "\n",
    "\t# if not safe\n",
    "\t\n",
    "\treliableQuestionClassifier()\n",
    "\treturn journalEntry\n",
    "\t\n",
    "\n",
    "\n",
    "checkHarmfulIntent(journalEntry):\n",
    "\tif not harm:\n",
    "\t\tjournalEntry.harmfulIntent = False\n",
    "\t\treturn \n",
    "\t\n",
    "\tjournalEntry.harmfulIntent = True\n",
    "\n",
    "\n",
    "\n",
    "generateCasualResponse():\n",
    "\t# generate empathy \n",
    "\t# return \n",
    "\n",
    "\n",
    "generateCatharticResponse():\n",
    "\t# generate empathy\n",
    "\t# if stage = 5: call cognitive reframing\n",
    "\t# else questionmapper\n",
    "\n",
    "\t# build response using empathy and questions \n",
    "\n",
    "\t# return \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fydp1",
   "language": "python",
   "name": "fydp1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
